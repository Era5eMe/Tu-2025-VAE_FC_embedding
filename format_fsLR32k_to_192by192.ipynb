{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifti2_filename(cifti1_path, output_dir):\n",
    "    basename = os.path.basename(cifti1_path)\n",
    "\n",
    "    # List of known CIFTI suffixes\n",
    "    known_suffixes = [\".dtseries.nii\", \".dconn.nii\", \".dscalar.nii\", \".dpconn.nii\"]\n",
    "\n",
    "    # Match and strip full suffix\n",
    "    for suffix in known_suffixes:\n",
    "        if basename.endswith(suffix):\n",
    "            stem = basename[: -len(suffix)]  # strip the full suffix\n",
    "            cifti2_name = f\"{stem}_cifti2{suffix}\"\n",
    "            return os.path.join(output_dir, cifti2_name)\n",
    "\n",
    "    raise ValueError(\"Unknown CIFTI suffix in filename\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_correlations(input_file, tmask):\n",
    "    if input_file.endswith(\".dtseries.nii\"):\n",
    "        cifti_img = nib.load(input_file)\n",
    "        cifti_data = cifti_img.get_fdata()\n",
    "        # cifti_header = cifti_img.header\n",
    "        bm_index_map = cifti_img.header.get_index_map(1)\n",
    "\n",
    "        # Initialize storage\n",
    "        vertex_indices = []\n",
    "        # Loop through the brain models in the index map\n",
    "        for bm in bm_index_map.brain_models:\n",
    "            structure = bm.brain_structure\n",
    "            if structure in ['CIFTI_STRUCTURE_CORTEX_LEFT', 'CIFTI_STRUCTURE_CORTEX_RIGHT']:\n",
    "                # Convert Cifti2VertexIndices to numpy array\n",
    "                offset = bm.index_offset\n",
    "                count = bm.index_count\n",
    "                vertex_indices.extend(range(offset, offset + count))\n",
    "\n",
    "        vertex_indices = np.array(vertex_indices)\n",
    "        cortex_ts = np.transpose(cifti_data[:, vertex_indices])\n",
    "        masked_cortex_ts = cortex_ts[:, tmask]\n",
    "        corr_matrix = np.corrcoef(masked_cortex_ts)\n",
    "        return corr_matrix\n",
    "    else:\n",
    "        raise ValueError(\"Input file must be a CIFTI-2 time-series file. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(corrs, transmat_path, img_size):\n",
    "    # assert corrs.shape == (59412, )\n",
    "    left_data, right_data = corrs[:29697, :], corrs[29697:, :]\n",
    "    left_transmat = sio.loadmat(os.path.join(transmat_path, \"Left_fMRI2Grid_192_by_192_NN.mat\"))\n",
    "    right_transmat = sio.loadmat(os.path.join(transmat_path, \"Right_fMRI2Grid_192_by_192_NN.mat\"))\n",
    "    \n",
    "    left_surf_data = np.reshape(left_transmat['grid_mapping'] @ left_data, (img_size, img_size, 1, -1), order='F')\n",
    "    right_surf_data = np.reshape(right_transmat['grid_mapping'] @ right_data, (img_size, img_size, 1, -1), order='F')\n",
    "\n",
    "    return left_surf_data, right_surf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_sample(left_surf_data, right_surf_data, sample_ratio=1.0):\n",
    "    assert left_surf_data.shape == right_surf_data.shape\n",
    "    if sample_ratio <= 0 or sample_ratio > 1.0:\n",
    "        raise ValueError(\"Please pick a sample ratio between 0 and 1. \")\n",
    "    img_size, _, _, sample_size = left_surf_data.shape\n",
    "    indices = np.random.choice(sample_size, sample_size*sample_ratio, replace=False)\n",
    "    sampled_left_surf_data = left_surf_data[:, :, :, indices]\n",
    "    sampled_right_surf_data  = right_surf_data[:, :, :, indices]\n",
    "    return sampled_left_surf_data, sampled_right_surf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(zdim):\n",
    "    pass\n",
    "\n",
    "def generate_loader(left_surf_data, right_surf_data, batch_size):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference(zdim, left_surf_data, right_surf_data, mode, batch_size, device):\n",
    "    model = load_model(zdim).to(device)\n",
    "    model.eval()\n",
    "    inference_loader = generate_loader(left_surf_data, right_surf_data, batch_size)\n",
    "\n",
    "    all_z_distributions = []\n",
    "    all_xL_recon = []\n",
    "    all_xR_recon = []\n",
    "    \n",
    "    for batch_idx, (xL, xR) in enumerate(inference_loader):\n",
    "        xL = xL.to(device)\n",
    "        xR = xR.to(device)\n",
    "        z_distribution = model._encode(xL, xR)\n",
    "        all_z_distributions.append(z_distribution.cpu().numpy())\n",
    "\n",
    "        if mode == \"both\":\n",
    "            mu = z_distribution[:, :zdim]\n",
    "            z = torch.tensor(mu).to(device)\n",
    "            xL_recon, xR_recon = model._decode(z)\n",
    "            all_xL_recon.append(xL_recon.cpu().numpy())\n",
    "            all_xR_recon.append(xR_recon.cpu().numpy())\n",
    "    \n",
    "    all_z_distributions = np.concatenate(all_z_distributions, axis=0)\n",
    "\n",
    "    if mode == \"encode\":\n",
    "        return all_z_distributions\n",
    "    elif mode == \"both\":\n",
    "        all_xL_recon = np.concatenate(all_xL_recon, axis=0)\n",
    "        all_xR_recon = np.concatenate(all_xR_recon, axis=0)\n",
    "        return all_z_distributions, all_xL_recon, all_xR_recon\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode. Choose 'encode' or 'both'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_representations(zs, labels):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_cifti_cohort_filepath = \"./data/cohort_files/cohortfiles_washu120.txt\"\n",
    "example_tmask_cohort_filepath = \"./data/tmask_files/tmasklist_washu120.txt\"\n",
    "\n",
    "cifti_cohort_df = pd.read_csv(example_cifti_cohort_filepath, delim_whitespace=True, header=None)\n",
    "tmask_cohort_df = pd.read_csv(example_tmask_cohort_filepath, delim_whitespace=True, header=None)\n",
    "\n",
    "example_idx = 111\n",
    "subj, cifti1_path = cifti_cohort_df.iloc[example_idx, :2].tolist()\n",
    "tmask_subj, tmask_path = tmask_cohort_df.iloc[example_idx, :].tolist()\n",
    "assert subj == tmask_subj\n",
    "tmask = np.loadtxt(tmask_path, dtype=int).astype(bool)\n",
    "\n",
    "cifti2_path = cifti2_filename(cifti1_path, \"./data/washu120/\")\n",
    "\n",
    "cifti_img = nib.load(cifti2_path)\n",
    "cifti_data = cifti_img.get_fdata()\n",
    "cifti_header = cifti_img.header\n",
    "bm_index_map = cifti_img.header.get_index_map(1)\n",
    "\n",
    "# Initialize storage\n",
    "vertex_indices = []\n",
    "# Loop through the brain models in the index map\n",
    "for bm in bm_index_map.brain_models:\n",
    "    structure = bm.brain_structure\n",
    "    if structure in ['CIFTI_STRUCTURE_CORTEX_LEFT', 'CIFTI_STRUCTURE_CORTEX_RIGHT']:\n",
    "        # Convert Cifti2VertexIndices to numpy array\n",
    "        offset = bm.index_offset\n",
    "        count = bm.index_count\n",
    "        vertex_indices.extend(range(offset, offset + count))\n",
    "\n",
    "vertex_indices = np.array(vertex_indices)\n",
    "cortex_ts = np.transpose(cifti_data[:, vertex_indices])\n",
    "masked_cortex_ts = cortex_ts[:, tmask]\n",
    "corr_matrix = np.corrcoef(masked_cortex_ts)\n",
    "# print(corr_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36864, 29696)\n",
      "(36864, 29716)\n"
     ]
    }
   ],
   "source": [
    "transmat_path = \"./mask\"\n",
    "left_mask_struct = sio.loadmat(os.path.join(transmat_path, \"Left_fMRI2Grid_192_by_192_NN.mat\"))\n",
    "left_mask = left_mask_struct['grid_mapping']\n",
    "right_mask_struct = sio.loadmat(os.path.join(transmat_path, \"Right_fMRI2Grid_192_by_192_NN.mat\"))\n",
    "right_mask = right_mask_struct['grid_mapping']\n",
    "print(left_mask.shape)\n",
    "print(right_mask.shape)\n",
    "# mask = sio.loadmat(os.path.join(transmat_path, \"MSE_Mask.mat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
